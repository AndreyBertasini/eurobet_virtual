{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "preleviamo dati da goldbet big match",
   "id": "df82b2140d668b51"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T21:09:29.963134Z",
     "start_time": "2024-11-21T21:09:23.006063Z"
    }
   },
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "class VirtualSportsCollector:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',\n",
    "            'Accept': 'application/json, text/plain, */*',\n",
    "            'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "            'Accept-Language': 'en-US,en;q=0.6',\n",
    "            'Origin': 'https://www.eurobet.it',\n",
    "            'X-EB-Accept-Language': 'it_IT',\n",
    "            'X-EB-MarketId': '5',\n",
    "            'X-EB-PlatformId': '1',\n",
    "            'Connection': 'keep-alive'\n",
    "        }\n",
    "        self.base_url = \"https://virtualservice.eurobet.it/virtual-winning-service/virtual-schedule/services/winningresult/55/22/{}\"\n",
    "        self.csv_filename = \"virtual_matches_data.csv\"\n",
    "        self.excel_filename = \"virtual_matches_data.xlsx\"\n",
    "\n",
    "    def create_match_id(self, row):\n",
    "        \"\"\"Create a unique identifier for each match\"\"\"\n",
    "        return f\"{row['date']}_{row['hour']}_{row['home_team']}_{row['away_team']}\"\n",
    "\n",
    "    def load_existing_data(self):\n",
    "        \"\"\"Load existing data from CSV if it exists\"\"\"\n",
    "        if os.path.exists(self.csv_filename):\n",
    "            return pd.read_csv(self.csv_filename)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    def get_virtual_data(self, start_date, end_date):\n",
    "        all_matches = []\n",
    "        current_date = start_date\n",
    "\n",
    "        while current_date <= end_date:\n",
    "            date_str = current_date.strftime(\"%d-%m-%Y\")\n",
    "            url = self.base_url.format(date_str)\n",
    "\n",
    "            try:\n",
    "                response = requests.get(url, headers=self.headers)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    if 'result' in data and 'groupDate' in data['result']:\n",
    "                        for group in data['result']['groupDate']:\n",
    "                            for event in group['events']:\n",
    "                                match_data = {\n",
    "                                    'date': event['date'],\n",
    "                                    'hour': event['hour'],\n",
    "                                    'home_team': event['eventDescription'].split(' - ')[0],\n",
    "                                    'away_team': event['eventDescription'].split(' - ')[1],\n",
    "                                    'score': event['finalResult'],\n",
    "                                    'home_goals': int(event['finalResult'].split('-')[0]),\n",
    "                                    'away_goals': int(event['finalResult'].split('-')[1]),\n",
    "                                    'datetime': pd.to_datetime(f\"{event['date']} {event['hour']}\", format='%d-%m-%Y %H:%M:%S')\n",
    "                                }\n",
    "\n",
    "                                for odd_group in event['oddGroup']:\n",
    "                                    if odd_group['betDescriptionAbbr'] == '1X2':\n",
    "                                        match_data['odds_1'] = odd_group['odds'][0]\n",
    "                                        match_data['result'] = odd_group['resultDescription'][0]\n",
    "                                    elif odd_group['betDescriptionAbbr'] == 'U/O 2.5':\n",
    "                                        match_data['over_under_25'] = odd_group['resultDescription'][0]\n",
    "                                        match_data['odds_over_under_25'] = odd_group['odds'][0]\n",
    "                                    elif odd_group['betDescriptionAbbr'] == 'Goal/No Goal':\n",
    "                                        match_data['goal_no_goal'] = odd_group['resultDescription'][0]\n",
    "                                        match_data['odds_goal_no_goal'] = odd_group['odds'][0]\n",
    "\n",
    "                                all_matches.append(match_data)\n",
    "\n",
    "                time.sleep(1)  # Respect rate limiting\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {date_str}: {e}\")\n",
    "\n",
    "            current_date += timedelta(days=1)\n",
    "\n",
    "        return pd.DataFrame(all_matches)\n",
    "\n",
    "    def merge_and_save_data(self, new_data):\n",
    "        \"\"\"Merge new data with existing data, remove duplicates, and save\"\"\"\n",
    "        existing_data = self.load_existing_data()\n",
    "\n",
    "        if not existing_data.empty:\n",
    "            # Convert datetime column in existing data if it's not already datetime\n",
    "            existing_data['datetime'] = pd.to_datetime(existing_data['datetime'])\n",
    "\n",
    "        # Combine existing and new data\n",
    "        combined_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "\n",
    "        # Create unique identifier for each match\n",
    "        combined_data['match_id'] = combined_data.apply(self.create_match_id, axis=1)\n",
    "\n",
    "        # Remove duplicates based on match_id\n",
    "        combined_data = combined_data.drop_duplicates(subset=['match_id'], keep='first')\n",
    "\n",
    "        # Sort by datetime in descending order (most recent first)\n",
    "        combined_data = combined_data.sort_values('datetime', ascending=False)\n",
    "\n",
    "        # Drop the match_id column as it's no longer needed\n",
    "        combined_data = combined_data.drop('match_id', axis=1)\n",
    "\n",
    "        # Save to CSV and Excel\n",
    "        combined_data.to_csv(self.csv_filename, index=False)\n",
    "        combined_data.to_excel(self.excel_filename, index=False)\n",
    "\n",
    "        return combined_data\n",
    "\n",
    "    def collect_data(self, days_back=1):\n",
    "        \"\"\"Main method to collect and process data\"\"\"\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days_back)\n",
    "\n",
    "        print(f\"Collecting data from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        new_data = self.get_virtual_data(start_date, end_date)\n",
    "        if not new_data.empty:\n",
    "            final_data = self.merge_and_save_data(new_data)\n",
    "            print(f\"Data saved successfully\")\n",
    "            print(f\"Total matches in database: {len(final_data)}\")\n",
    "            print(f\"Files saved as: {self.csv_filename} and {self.excel_filename}\")\n",
    "        else:\n",
    "            print(\"No new data collected\")\n",
    "\n",
    "def main(days_back=1):\n",
    "    collector = VirtualSportsCollector()\n",
    "    collector.collect_data(days_back)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # Default 90 days"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data from 2024-11-20 to 2024-11-21\n",
      "Data saved successfully\n",
      "Total matches in database: 19794\n",
      "Files saved as: virtual_matches_data.csv and virtual_matches_data.xlsx\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "predizione",
   "id": "914ffe05d6d72016"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T21:34:16.599927Z",
     "start_time": "2024-11-21T21:34:16.581531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "class VirtualMatchPredictor:\n",
    "    def __init__(self):\n",
    "        self.markov_matrix = None\n",
    "        self.state_counts = defaultdict(int)\n",
    "        self.transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.prior_draw_probability = None\n",
    "        self.model_metrics = {}\n",
    "        self.predictions_history = []\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Preprocessa il DataFrame per l'analisi.\"\"\"\n",
    "        df = df.copy()\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        df['hour'] = pd.to_datetime(df['hour'], format='%H:%M:%S').dt.hour\n",
    "        return df.sort_values('datetime')\n",
    "\n",
    "    def build_markov_chain(self, df):\n",
    "        \"\"\"Costruisce la catena di Markov dai risultati.\"\"\"\n",
    "        results = df['result'].tolist()\n",
    "\n",
    "        # Conta le transizioni\n",
    "        for i in range(len(results)-1):\n",
    "            current_state = results[i]\n",
    "            next_state = results[i+1]\n",
    "            self.state_counts[current_state] += 1\n",
    "            self.transition_counts[current_state][next_state] += 1\n",
    "\n",
    "        # Calcola la matrice di transizione\n",
    "        states = ['1', '2', 'X']\n",
    "        self.markov_matrix = np.zeros((3, 3))\n",
    "\n",
    "        for i, current in enumerate(states):\n",
    "            total = sum(self.transition_counts[current].values())\n",
    "            if total > 0:\n",
    "                for j, next_state in enumerate(states):\n",
    "                    self.markov_matrix[i][j] = self.transition_counts[current][next_state] / total\n",
    "\n",
    "        return self.markov_matrix\n",
    "\n",
    "    def calculate_team_statistics(self, df):\n",
    "        \"\"\"Calcola statistiche per squadra.\"\"\"\n",
    "        team_stats = {}\n",
    "\n",
    "        for team in set(df['home_team'].unique()) | set(df['away_team'].unique()):\n",
    "            home_games = df[df['home_team'] == team]\n",
    "            away_games = df[df['away_team'] == team]\n",
    "\n",
    "            stats = {\n",
    "                'total_games': len(home_games) + len(away_games),\n",
    "                'goals_scored': home_games['home_goals'].sum() + away_games['away_goals'].sum(),\n",
    "                'goals_conceded': home_games['away_goals'].sum() + away_games['home_goals'].sum(),\n",
    "                'draws': len(home_games[home_games['result'] == 'X']) + len(away_games[away_games['result'] == 'X']),\n",
    "                'draw_percentage': 0\n",
    "            }\n",
    "\n",
    "            if stats['total_games'] > 0:\n",
    "                stats['draw_percentage'] = (stats['draws'] / stats['total_games']) * 100\n",
    "\n",
    "            team_stats[team] = stats\n",
    "\n",
    "        return team_stats\n",
    "\n",
    "    def evaluate_model(self, df_test):\n",
    "        \"\"\"Valuta le prestazioni del modello.\"\"\"\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for i in range(len(df_test)-1):\n",
    "            subset = df_test.iloc[:i+1]\n",
    "            last_result = subset['result'].iloc[-1]\n",
    "            pred = self.calculate_draw_probability_bayes(subset, last_result)\n",
    "\n",
    "            # Converti probabilità in previsione binaria (pareggio o no)\n",
    "            pred_binary = 'X' if pred > self.prior_draw_probability else '1'\n",
    "            actual = df_test['result'].iloc[i+1]\n",
    "\n",
    "            y_true.append(actual)\n",
    "            y_pred.append(pred_binary)\n",
    "\n",
    "        # Calcola metriche\n",
    "        self.model_metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred, average='weighted', labels=['X']),\n",
    "            'recall': recall_score(y_true, y_pred, average='weighted', labels=['X']),\n",
    "            'f1': f1_score(y_true, y_pred, average='weighted', labels=['X']),\n",
    "            'confusion_matrix': confusion_matrix(y_true, y_pred),\n",
    "            'classification_report': classification_report(y_true, y_pred)\n",
    "        }\n",
    "\n",
    "        return self.model_metrics\n",
    "\n",
    "    def generate_prediction_report(self, next_match_data, prediction_results):\n",
    "        \"\"\"Genera un report dettagliato per la prossima partita.\"\"\"\n",
    "        report = {\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"match_details\": {\n",
    "                \"home_team\": next_match_data['home_team'],\n",
    "                \"away_team\": next_match_data['away_team'],\n",
    "                \"datetime\": next_match_data['datetime']\n",
    "            },\n",
    "            \"prediction_details\": {\n",
    "                \"draw_probability\": round(prediction_results['draw_probability'] * 100, 2),\n",
    "                \"confidence_level\": self._calculate_confidence_level(prediction_results['draw_probability']),\n",
    "                \"historical_context\": {\n",
    "                    \"prior_draw_probability\": round(self.prior_draw_probability * 100, 2),\n",
    "                    \"hour_trend\": self._get_hour_trend(next_match_data['hour'])\n",
    "                }\n",
    "            },\n",
    "            \"model_performance\": {\n",
    "                \"accuracy\": round(self.model_metrics['accuracy'] * 100, 2),\n",
    "                \"precision_for_draws\": round(self.model_metrics['precision'] * 100, 2),\n",
    "                \"recall_for_draws\": round(self.model_metrics['recall'] * 100, 2),\n",
    "                \"f1_score\": round(self.model_metrics['f1'] * 100, 2)\n",
    "            },\n",
    "            \"recommendations\": self._generate_recommendations(prediction_results['draw_probability'])\n",
    "        }\n",
    "\n",
    "        # Salva il report\n",
    "        filename = f\"match_prediction_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(report, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        return report\n",
    "\n",
    "    def _calculate_confidence_level(self, probability):\n",
    "        \"\"\"Calcola il livello di confidenza della previsione.\"\"\"\n",
    "        if probability > 0.7: return \"MOLTO ALTO\"\n",
    "        elif probability > 0.6: return \"ALTO\"\n",
    "        elif probability > 0.5: return \"MEDIO\"\n",
    "        elif probability > 0.4: return \"BASSO\"\n",
    "        else: return \"MOLTO BASSO\"\n",
    "\n",
    "    def _get_hour_trend(self, hour):\n",
    "        \"\"\"Analizza il trend orario.\"\"\"\n",
    "        if not hasattr(self, 'hourly_trends'):\n",
    "            return \"Dati insufficienti\"\n",
    "\n",
    "        trend = self.hourly_trends.get(hour, 0)\n",
    "        if trend > 0.3: return \"Ora favorevole ai pareggi\"\n",
    "        elif trend < 0.1: return \"Ora sfavorevole ai pareggi\"\n",
    "        else: return \"Trend orario neutro\"\n",
    "\n",
    "    def _generate_recommendations(self, draw_probability):\n",
    "        \"\"\"Genera raccomandazioni basate sulla probabilità.\"\"\"\n",
    "        recommendations = []\n",
    "\n",
    "        if draw_probability > 0.6:\n",
    "            recommendations.append(\"Alta probabilità di pareggio - Situazione molto interessante\")\n",
    "        elif draw_probability > 0.5:\n",
    "            recommendations.append(\"Probabilità media di pareggio - Valutare altri fattori\")\n",
    "        else:\n",
    "            recommendations.append(\"Bassa probabilità di pareggio - Meglio evitare\")\n",
    "\n",
    "        recommendations.append(f\"Confidenza del modello: {self.model_metrics['accuracy']:.2%}\")\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    def plot_confusion_matrix(self):\n",
    "        \"\"\"Visualizza la matrice di confusione.\"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(self.model_metrics['confusion_matrix'],\n",
    "                   annot=True,\n",
    "                   fmt='d',\n",
    "                   cmap='Blues',\n",
    "                   xticklabels=['1', '2', 'X'],\n",
    "                   yticklabels=['1', '2', 'X'])\n",
    "        plt.title('Matrice di Confusione')\n",
    "        plt.ylabel('Reale')\n",
    "        plt.xlabel('Previsto')\n",
    "\n",
    "        # Salva il grafico\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "\n",
    "    def plot_markov_transitions(self):\n",
    "        \"\"\"Visualizza le transizioni di Markov.\"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(self.markov_matrix,\n",
    "                   annot=True,\n",
    "                   fmt='.2f',\n",
    "                   cmap='YlOrRd',\n",
    "                   xticklabels=['1', '2', 'X'],\n",
    "                   yticklabels=['1', '2', 'X'])\n",
    "        plt.title('Matrice di Transizione di Markov')\n",
    "        plt.ylabel('Stato Attuale')\n",
    "        plt.xlabel('Stato Successivo')\n",
    "\n",
    "        # Salva il grafico\n",
    "        plt.savefig('markov_transitions.png')\n",
    "        plt.close()\n",
    "\n",
    "    def predict_next_draw(self, df, next_match_data):\n",
    "        \"\"\"Predice la probabilità di pareggio per il prossimo match.\"\"\"\n",
    "        # Preprocessa i dati\n",
    "        df = self.preprocess_data(df)\n",
    "\n",
    "        # Costruisce la catena di Markov\n",
    "        self.build_markov_chain(df)\n",
    "\n",
    "        # Calcola la probabilità con Bayes\n",
    "        last_result = df['result'].iloc[-1]\n",
    "        draw_prob = self.calculate_draw_probability_bayes(df, last_result)\n",
    "\n",
    "        # Analizza i trend orari\n",
    "        self.hourly_trends = self.analyze_daily_trends(df)\n",
    "\n",
    "        # Valuta il modello\n",
    "        self.evaluate_model(df)\n",
    "\n",
    "        # Genera i grafici\n",
    "        self.plot_confusion_matrix()\n",
    "        self.plot_markov_transitions()\n",
    "\n",
    "        # Prepara i risultati\n",
    "        prediction_results = {\n",
    "            'draw_probability': draw_prob,\n",
    "            'hourly_trends': self.hourly_trends,\n",
    "            'markov_matrix': self.markov_matrix,\n",
    "            'model_metrics': self.model_metrics\n",
    "        }\n",
    "\n",
    "        # Genera e salva il report\n",
    "        report = self.generate_prediction_report(next_match_data, prediction_results)\n",
    "\n",
    "        return prediction_results, report\n",
    "\n",
    "def analyze_matches(df, next_match_data):\n",
    "    \"\"\"Funzione principale per l'analisi delle partite.\"\"\"\n",
    "    predictor = VirtualMatchPredictor()\n",
    "\n",
    "    # Converti il DataFrame se necessario\n",
    "    df = pd.read_csv(StringIO(df)) if isinstance(df, str) else df\n",
    "\n",
    "    # Esegui la predizione\n",
    "    prediction_results, report = predictor.predict_next_draw(df, next_match_data)\n",
    "\n",
    "    return prediction_results, report\n",
    "\n",
    "# Esempio di utilizzo:\n",
    "\"\"\"\n",
    "next_match_data = {\n",
    "    'home_team': 'JUV',\n",
    "    'away_team': 'INT',\n",
    "    'datetime': '2024-11-22 20:00:00',\n",
    "    'hour': 20\n",
    "}\n",
    "\n",
    "results, report = analyze_matches(df, next_match_data)\n",
    "\"\"\""
   ],
   "id": "c6310d1f5de9f5d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnext_match_data = {\\n    'home_team': 'JUV',\\n    'away_team': 'INT',\\n    'datetime': '2024-11-22 20:00:00',\\n    'hour': 20\\n}\\n\\nresults, report = analyze_matches(df, next_match_data)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dati da prevedere.",
   "id": "5c5547cee97ff7c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T21:46:29.301223Z",
     "start_time": "2024-11-21T21:46:22.344823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class VirtualOddsCollector:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',\n",
    "            'Accept': 'application/json, text/plain, */*',\n",
    "            'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "            'Accept-Language': 'en-US,en;q=0.6',\n",
    "            'Origin': 'https://www.eurobet.it',\n",
    "            'X-EB-Accept-Language': 'it_IT',\n",
    "            'X-EB-MarketId': '5',\n",
    "            'X-EB-PlatformId': '1',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Referer': 'https://www.eurobet.it/'\n",
    "        }\n",
    "        self.data_dir = Path('data')\n",
    "        self.data_dir.mkdir(exist_ok=True)\n",
    "        self.csv_filename = self.data_dir / 'virtual_odds_detail.csv'\n",
    "        self.base_url = \"https://virtualservice.eurobet.it/virtual-detail-service/virtual-schedule/services/22/sport/{}\"\n",
    "\n",
    "        print(f\"File will be saved to: {self.csv_filename}\")\n",
    "\n",
    "    def get_match_odds(self, match_code):\n",
    "        \"\"\"Get odds for a specific match\"\"\"\n",
    "        url = self.base_url.format(match_code)\n",
    "        try:\n",
    "            print(f\"Fetching data for match code: {match_code}\")\n",
    "            response = requests.get(url, headers=self.headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            if 'result' not in data or 'eventdetail' not in data['result']:\n",
    "                print(f\"No valid data found for match {match_code}\")\n",
    "                return None\n",
    "\n",
    "            event_info = data['result']['eventdetail']['eventInfo']\n",
    "            bet_groups = data['result']['eventdetail']['betGroupList']\n",
    "\n",
    "            match_data = {\n",
    "                'match_code': match_code,\n",
    "                'timestamp': datetime.fromtimestamp(event_info['eventData']/1000).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'home_team': event_info['teamHomeDescription'],\n",
    "                'away_team': event_info['teamAwayDescription'],\n",
    "                'channel': event_info['channelDescription'],\n",
    "                'event_code': event_info['eventCode'],\n",
    "                'program_code': event_info['programCode'],\n",
    "                'collection_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "\n",
    "            for bet_group in bet_groups:\n",
    "                bet_type = bet_group['betDescription']\n",
    "                market_id = bet_group['marketId']\n",
    "\n",
    "                if bet_group['oddGroupList'] and bet_group['oddGroupList'][0]['oddList']:\n",
    "                    odds = bet_group['oddGroupList'][0]['oddList']\n",
    "\n",
    "                    for odd in odds:\n",
    "                        desc = odd['oddDescription']\n",
    "                        value = odd['oddValue']\n",
    "                        result_code = odd['resultCode']\n",
    "\n",
    "                        key_base = f\"{bet_type}_{desc}\".lower().replace('/', '_').replace(' ', '_')\n",
    "                        match_data[f\"{key_base}_odds\"] = value\n",
    "                        match_data[f\"{key_base}_code\"] = result_code\n",
    "\n",
    "            print(f\"Successfully collected odds for {match_data['home_team']} vs {match_data['away_team']}\")\n",
    "            return match_data\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Network error for match {match_code}: {e}\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error for match {match_code}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for match {match_code}: {e}\")\n",
    "        return None\n",
    "\n",
    "    def collect_matches(self, match_codes):\n",
    "        \"\"\"Collect odds for multiple matches\"\"\"\n",
    "        all_matches = []\n",
    "\n",
    "        print(f\"\\nStarting collection for match codes: {match_codes}\")\n",
    "\n",
    "        for match_code in match_codes:\n",
    "            match_data = self.get_match_odds(match_code)\n",
    "            if match_data:\n",
    "                all_matches.append(match_data)\n",
    "            time.sleep(1)\n",
    "\n",
    "        if not all_matches:\n",
    "            print(\"No match data collected!\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(all_matches)\n",
    "\n",
    "        if self.csv_filename.exists():\n",
    "            try:\n",
    "                existing_df = pd.read_csv(self.csv_filename)\n",
    "                print(f\"Loaded {len(existing_df)} existing records\")\n",
    "                df = pd.concat([existing_df, df], ignore_index=True)\n",
    "                df = df.drop_duplicates(subset=['match_code', 'timestamp'], keep='last')\n",
    "                print(f\"After merging and removing duplicates: {len(df)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading existing data: {e}\")\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.sort_values('timestamp', ascending=False)\n",
    "\n",
    "        try:\n",
    "            df.to_csv(self.csv_filename, index=False)\n",
    "            print(f\"\\nSuccessfully saved data to {self.csv_filename}\")\n",
    "            print(f\"Total matches in database: {len(df)}\")\n",
    "\n",
    "            print(\"\\nPreview of saved data:\")\n",
    "            basic_cols = ['timestamp', 'home_team', 'away_team']\n",
    "            odds_cols = [col for col in df.columns if '1x2_finale' in col and 'odds' in col]\n",
    "            print(df[basic_cols + odds_cols].head())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving data: {e}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "# Variabili per generare i codici delle partite\n",
    "BASE_CODE = \"55_2402405092\"  # Codice base\n",
    "START_NUMBER = 384  # Numero iniziale\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Genera 5 codici incrementando di 2 ogni volta\n",
    "    match_codes = []\n",
    "    current_number = START_NUMBER\n",
    "\n",
    "    for _ in range(5):\n",
    "        match_code = f\"{BASE_CODE}_{current_number}\"\n",
    "        match_codes.append(match_code)\n",
    "        current_number += 2\n",
    "\n",
    "    collector = VirtualOddsCollector()\n",
    "    collector.collect_matches(match_codes)"
   ],
   "id": "a0dd4bab52375c25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File will be saved to: data\\virtual_odds_detail.csv\n",
      "\n",
      "Starting collection for match codes: ['55_2402405092_384', '55_2402405092_386', '55_2402405092_388', '55_2402405092_390', '55_2402405092_392']\n",
      "Fetching data for match code: 55_2402405092_384\n",
      "Successfully collected odds for LAZ vs JUV\n",
      "Fetching data for match code: 55_2402405092_386\n",
      "Successfully collected odds for ROM vs NAP\n",
      "Fetching data for match code: 55_2402405092_388\n",
      "Successfully collected odds for MIL vs FIO\n",
      "Fetching data for match code: 55_2402405092_390\n",
      "Successfully collected odds for LAZ vs INT\n",
      "Fetching data for match code: 55_2402405092_392\n",
      "Successfully collected odds for JUV vs NAP\n",
      "Loaded 3 existing records\n",
      "After merging and removing duplicates: 6 records\n",
      "\n",
      "Successfully saved data to data\\virtual_odds_detail.csv\n",
      "Total matches in database: 6\n",
      "\n",
      "Preview of saved data:\n",
      "            timestamp home_team away_team  1x2_finale_1_odds  \\\n",
      "7 2024-11-21 22:55:00       JUV       NAP                183   \n",
      "6 2024-11-21 22:50:00       LAZ       INT                216   \n",
      "5 2024-11-21 22:45:00       MIL       FIO                221   \n",
      "4 2024-11-21 22:40:00       ROM       NAP                221   \n",
      "3 2024-11-21 22:35:00       LAZ       JUV                239   \n",
      "\n",
      "   1x2_finale_x_odds  1x2_finale_2_odds  \n",
      "7                353                326  \n",
      "6                319                277  \n",
      "5                318                271  \n",
      "4                315                272  \n",
      "3                307                255  \n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
