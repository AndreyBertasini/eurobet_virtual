{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-21T20:50:26.052036Z"
    }
   },
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "class VirtualSportsCollector:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',\n",
    "            'Accept': 'application/json, text/plain, */*',\n",
    "            'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "            'Accept-Language': 'en-US,en;q=0.6',\n",
    "            'Origin': 'https://www.eurobet.it',\n",
    "            'X-EB-Accept-Language': 'it_IT',\n",
    "            'X-EB-MarketId': '5',\n",
    "            'X-EB-PlatformId': '1',\n",
    "            'Connection': 'keep-alive'\n",
    "        }\n",
    "        self.base_url = \"https://virtualservice.eurobet.it/virtual-winning-service/virtual-schedule/services/winningresult/55/22/{}\"\n",
    "        self.csv_filename = \"virtual_matches_data.csv\"\n",
    "        self.excel_filename = \"virtual_matches_data.xlsx\"\n",
    "\n",
    "    def create_match_id(self, row):\n",
    "        \"\"\"Create a unique identifier for each match\"\"\"\n",
    "        return f\"{row['date']}_{row['hour']}_{row['home_team']}_{row['away_team']}\"\n",
    "\n",
    "    def load_existing_data(self):\n",
    "        \"\"\"Load existing data from CSV if it exists\"\"\"\n",
    "        if os.path.exists(self.csv_filename):\n",
    "            return pd.read_csv(self.csv_filename)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    def get_virtual_data(self, start_date, end_date):\n",
    "        all_matches = []\n",
    "        current_date = start_date\n",
    "\n",
    "        while current_date <= end_date:\n",
    "            date_str = current_date.strftime(\"%d-%m-%Y\")\n",
    "            url = self.base_url.format(date_str)\n",
    "\n",
    "            try:\n",
    "                response = requests.get(url, headers=self.headers)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    if 'result' in data and 'groupDate' in data['result']:\n",
    "                        for group in data['result']['groupDate']:\n",
    "                            for event in group['events']:\n",
    "                                match_data = {\n",
    "                                    'date': event['date'],\n",
    "                                    'hour': event['hour'],\n",
    "                                    'home_team': event['eventDescription'].split(' - ')[0],\n",
    "                                    'away_team': event['eventDescription'].split(' - ')[1],\n",
    "                                    'score': event['finalResult'],\n",
    "                                    'home_goals': int(event['finalResult'].split('-')[0]),\n",
    "                                    'away_goals': int(event['finalResult'].split('-')[1]),\n",
    "                                    'datetime': pd.to_datetime(f\"{event['date']} {event['hour']}\", format='%d-%m-%Y %H:%M:%S')\n",
    "                                }\n",
    "\n",
    "                                for odd_group in event['oddGroup']:\n",
    "                                    if odd_group['betDescriptionAbbr'] == '1X2':\n",
    "                                        match_data['odds_1'] = odd_group['odds'][0]\n",
    "                                        match_data['result'] = odd_group['resultDescription'][0]\n",
    "                                    elif odd_group['betDescriptionAbbr'] == 'U/O 2.5':\n",
    "                                        match_data['over_under_25'] = odd_group['resultDescription'][0]\n",
    "                                        match_data['odds_over_under_25'] = odd_group['odds'][0]\n",
    "                                    elif odd_group['betDescriptionAbbr'] == 'Goal/No Goal':\n",
    "                                        match_data['goal_no_goal'] = odd_group['resultDescription'][0]\n",
    "                                        match_data['odds_goal_no_goal'] = odd_group['odds'][0]\n",
    "\n",
    "                                all_matches.append(match_data)\n",
    "\n",
    "                time.sleep(1)  # Respect rate limiting\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {date_str}: {e}\")\n",
    "\n",
    "            current_date += timedelta(days=1)\n",
    "\n",
    "        return pd.DataFrame(all_matches)\n",
    "\n",
    "    def merge_and_save_data(self, new_data):\n",
    "        \"\"\"Merge new data with existing data, remove duplicates, and save\"\"\"\n",
    "        existing_data = self.load_existing_data()\n",
    "\n",
    "        if not existing_data.empty:\n",
    "            # Convert datetime column in existing data if it's not already datetime\n",
    "            existing_data['datetime'] = pd.to_datetime(existing_data['datetime'])\n",
    "\n",
    "        # Combine existing and new data\n",
    "        combined_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "\n",
    "        # Create unique identifier for each match\n",
    "        combined_data['match_id'] = combined_data.apply(self.create_match_id, axis=1)\n",
    "\n",
    "        # Remove duplicates based on match_id\n",
    "        combined_data = combined_data.drop_duplicates(subset=['match_id'], keep='first')\n",
    "\n",
    "        # Sort by datetime in descending order (most recent first)\n",
    "        combined_data = combined_data.sort_values('datetime', ascending=False)\n",
    "\n",
    "        # Drop the match_id column as it's no longer needed\n",
    "        combined_data = combined_data.drop('match_id', axis=1)\n",
    "\n",
    "        # Save to CSV and Excel\n",
    "        combined_data.to_csv(self.csv_filename, index=False)\n",
    "        combined_data.to_excel(self.excel_filename, index=False)\n",
    "\n",
    "        return combined_data\n",
    "\n",
    "    def collect_data(self, days_back=90):\n",
    "        \"\"\"Main method to collect and process data\"\"\"\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days_back)\n",
    "\n",
    "        print(f\"Collecting data from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        new_data = self.get_virtual_data(start_date, end_date)\n",
    "        if not new_data.empty:\n",
    "            final_data = self.merge_and_save_data(new_data)\n",
    "            print(f\"Data saved successfully\")\n",
    "            print(f\"Total matches in database: {len(final_data)}\")\n",
    "            print(f\"Files saved as: {self.csv_filename} and {self.excel_filename}\")\n",
    "        else:\n",
    "            print(\"No new data collected\")\n",
    "\n",
    "def main(days_back=90):\n",
    "    collector = VirtualSportsCollector()\n",
    "    collector.collect_data(days_back)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # Default 90 days"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data from 2024-08-23 to 2024-11-21\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
