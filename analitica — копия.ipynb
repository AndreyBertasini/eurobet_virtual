{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "preleviamo dati da goldbet big match",
   "id": "df82b2140d668b51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "22a4112fd4edfb93"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T22:31:46.735975Z",
     "start_time": "2024-11-21T22:31:39.933341Z"
    }
   },
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "class VirtualSportsCollector:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',\n",
    "            'Accept': 'application/json, text/plain, */*',\n",
    "            'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "            'Accept-Language': 'en-US,en;q=0.6',\n",
    "            'Origin': 'https://www.eurobet.it',\n",
    "            'X-EB-Accept-Language': 'it_IT',\n",
    "            'X-EB-MarketId': '5',\n",
    "            'X-EB-PlatformId': '1',\n",
    "            'Connection': 'keep-alive'\n",
    "        }\n",
    "        self.base_url = \"https://virtualservice.eurobet.it/virtual-winning-service/virtual-schedule/services/winningresult/55/22/{}\"\n",
    "        self.csv_filename = \"virtual_matches_data.csv\"\n",
    "        self.excel_filename = \"virtual_matches_data.xlsx\"\n",
    "\n",
    "    def create_match_id(self, row):\n",
    "        \"\"\"Create a unique identifier for each match\"\"\"\n",
    "        return f\"{row['date']}_{row['hour']}_{row['home_team']}_{row['away_team']}\"\n",
    "\n",
    "    def load_existing_data(self):\n",
    "        \"\"\"Load existing data from CSV if it exists\"\"\"\n",
    "        if os.path.exists(self.csv_filename):\n",
    "            return pd.read_csv(self.csv_filename)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    def get_virtual_data(self, start_date, end_date):\n",
    "        all_matches = []\n",
    "        current_date = start_date\n",
    "\n",
    "        while current_date <= end_date:\n",
    "            date_str = current_date.strftime(\"%d-%m-%Y\")\n",
    "            url = self.base_url.format(date_str)\n",
    "\n",
    "            try:\n",
    "                response = requests.get(url, headers=self.headers)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    if 'result' in data and 'groupDate' in data['result']:\n",
    "                        for group in data['result']['groupDate']:\n",
    "                            for event in group['events']:\n",
    "                                match_data = {\n",
    "                                    'date': event['date'],\n",
    "                                    'hour': event['hour'],\n",
    "                                    'home_team': event['eventDescription'].split(' - ')[0],\n",
    "                                    'away_team': event['eventDescription'].split(' - ')[1],\n",
    "                                    'score': event['finalResult'],\n",
    "                                    'home_goals': int(event['finalResult'].split('-')[0]),\n",
    "                                    'away_goals': int(event['finalResult'].split('-')[1]),\n",
    "                                    'datetime': pd.to_datetime(f\"{event['date']} {event['hour']}\", format='%d-%m-%Y %H:%M:%S')\n",
    "                                }\n",
    "\n",
    "                                for odd_group in event['oddGroup']:\n",
    "                                    if odd_group['betDescriptionAbbr'] == '1X2':\n",
    "                                        match_data['odds_1'] = odd_group['odds'][0]\n",
    "                                        match_data['result'] = odd_group['resultDescription'][0]\n",
    "                                    elif odd_group['betDescriptionAbbr'] == 'U/O 2.5':\n",
    "                                        match_data['over_under_25'] = odd_group['resultDescription'][0]\n",
    "                                        match_data['odds_over_under_25'] = odd_group['odds'][0]\n",
    "                                    elif odd_group['betDescriptionAbbr'] == 'Goal/No Goal':\n",
    "                                        match_data['goal_no_goal'] = odd_group['resultDescription'][0]\n",
    "                                        match_data['odds_goal_no_goal'] = odd_group['odds'][0]\n",
    "\n",
    "                                all_matches.append(match_data)\n",
    "\n",
    "                time.sleep(1)  # Respect rate limiting\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {date_str}: {e}\")\n",
    "\n",
    "            current_date += timedelta(days=1)\n",
    "\n",
    "        return pd.DataFrame(all_matches)\n",
    "\n",
    "    def merge_and_save_data(self, new_data):\n",
    "        \"\"\"Merge new data with existing data, remove duplicates, and save\"\"\"\n",
    "        existing_data = self.load_existing_data()\n",
    "\n",
    "        if not existing_data.empty:\n",
    "            # Convert datetime column in existing data if it's not already datetime\n",
    "            existing_data['datetime'] = pd.to_datetime(existing_data['datetime'])\n",
    "\n",
    "        # Combine existing and new data\n",
    "        combined_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "\n",
    "        # Create unique identifier for each match\n",
    "        combined_data['match_id'] = combined_data.apply(self.create_match_id, axis=1)\n",
    "\n",
    "        # Remove duplicates based on match_id\n",
    "        combined_data = combined_data.drop_duplicates(subset=['match_id'], keep='first')\n",
    "\n",
    "        # Sort by datetime in descending order (most recent first)\n",
    "        combined_data = combined_data.sort_values('datetime', ascending=False)\n",
    "\n",
    "        # Drop the match_id column as it's no longer needed\n",
    "        combined_data = combined_data.drop('match_id', axis=1)\n",
    "\n",
    "        # Save to CSV and Excel\n",
    "        combined_data.to_csv(self.csv_filename, index=False)\n",
    "        combined_data.to_excel(self.excel_filename, index=False)\n",
    "\n",
    "        return combined_data\n",
    "\n",
    "    def collect_data(self, days_back=1):\n",
    "        \"\"\"Main method to collect and process data\"\"\"\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days_back)\n",
    "\n",
    "        print(f\"Collecting data from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        new_data = self.get_virtual_data(start_date, end_date)\n",
    "        if not new_data.empty:\n",
    "            final_data = self.merge_and_save_data(new_data)\n",
    "            print(f\"Data saved successfully\")\n",
    "            print(f\"Total matches in database: {len(final_data)}\")\n",
    "            print(f\"Files saved as: {self.csv_filename} and {self.excel_filename}\")\n",
    "        else:\n",
    "            print(\"No new data collected\")\n",
    "\n",
    "def main(days_back=1):\n",
    "    collector = VirtualSportsCollector()\n",
    "    collector.collect_data(days_back)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # Default 90 days"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data from 2024-11-20 to 2024-11-21\n",
      "Data saved successfully\n",
      "Total matches in database: 19811\n",
      "Files saved as: virtual_matches_data.csv and virtual_matches_data.xlsx\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "predizione",
   "id": "914ffe05d6d72016"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T22:48:56.665622Z",
     "start_time": "2024-11-21T22:48:27.607672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class SoccerPredictor:\n",
    "    def __init__(self):\n",
    "        self.team_encoder = LabelEncoder()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.lstm_model = None\n",
    "        self.sequence_length = 3\n",
    "\n",
    "    def prepare_features(self, df):\n",
    "        df = df.copy()\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        df = df.sort_values('datetime')\n",
    "\n",
    "        # Base features\n",
    "        features = pd.DataFrame({\n",
    "            'datetime': df['datetime'],\n",
    "            'home_team': df['home_team'],\n",
    "            'away_team': df['away_team'],\n",
    "            'odds_1': df['odds_1'].astype(float)\n",
    "        })\n",
    "\n",
    "        # Encode teams\n",
    "        all_teams = pd.concat([df['home_team'], df['away_team']]).unique()\n",
    "        self.team_encoder.fit(all_teams)\n",
    "        features['home_team_enc'] = self.team_encoder.transform(df['home_team'])\n",
    "        features['away_team_enc'] = self.team_encoder.transform(df['away_team'])\n",
    "\n",
    "        # Calculate team stats\n",
    "        for team in all_teams:\n",
    "            home_matches = df[df['home_team'] == team]\n",
    "            away_matches = df[df['away_team'] == team]\n",
    "\n",
    "            home_rolling = home_matches['home_goals'].rolling(3, min_periods=1).mean()\n",
    "            away_rolling = away_matches['away_goals'].rolling(3, min_periods=1).mean()\n",
    "\n",
    "            team_idx = self.team_encoder.transform([team])[0]\n",
    "            features.loc[features['home_team_enc'] == team_idx, 'home_rolling_goals'] = home_rolling.values\n",
    "            features.loc[features['away_team_enc'] == team_idx, 'away_rolling_goals'] = away_rolling.values\n",
    "\n",
    "        feature_cols = ['home_team_enc', 'away_team_enc', 'odds_1', 'home_rolling_goals', 'away_rolling_goals']\n",
    "        X = features[feature_cols].fillna(0)\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "\n",
    "        y = (df['result'] == 'X').astype(int)\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "        X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "        return X_train, X_valid, X_test, y_train, y_valid, y_test, features[['datetime', 'home_team', 'away_team']]\n",
    "\n",
    "    def create_sequences(self, features):\n",
    "        sequences = [features[i:i + self.sequence_length] for i in range(len(features) - self.sequence_length + 1)]\n",
    "        return np.array(sequences)\n",
    "\n",
    "    def train_model(self, df):\n",
    "        try:\n",
    "            X_train, X_valid, X_test, y_train, y_valid, y_test, _ = self.prepare_features(df)\n",
    "\n",
    "            X_seq = self.create_sequences(X_train)\n",
    "            y_seq = y_train[self.sequence_length - 1:]\n",
    "\n",
    "            self.lstm_model = Sequential([\n",
    "                LSTM(64, input_shape=(self.sequence_length, X_train.shape[1])),\n",
    "                BatchNormalization(),\n",
    "                Dropout(0.3),\n",
    "                Dense(32, activation='relu'),\n",
    "                Dropout(0.2),\n",
    "                Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "\n",
    "            self.lstm_model.compile(\n",
    "                optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            self.lstm_model.fit(\n",
    "                X_seq, y_seq, epochs=30, batch_size=32,\n",
    "                validation_split=0.2, callbacks=[EarlyStopping(patience=5, restore_best_weights=True)], verbose=0\n",
    "            )\n",
    "\n",
    "            lstm_pred = (self.lstm_model.predict(self.create_sequences(X_train)) > 0.5).flatten()\n",
    "\n",
    "            return {\n",
    "                'accuracy': accuracy_score(y_seq, lstm_pred),\n",
    "                'precision': precision_score(y_seq, lstm_pred),\n",
    "                'recall': recall_score(y_seq, lstm_pred),\n",
    "                'f1': f1_score(y_seq, lstm_pred)\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Training error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def predict_draws(self, new_data):\n",
    "        try:\n",
    "            X_new, _, _, _, _, _, match_info = self.prepare_features(new_data)\n",
    "            X_seq = self.create_sequences(X_new)\n",
    "\n",
    "            lstm_probs = self.lstm_model.predict(X_seq).flatten()\n",
    "\n",
    "            min_len = min(len(lstm_probs), len(match_info['datetime'].iloc[self.sequence_length - 1:]))\n",
    "\n",
    "            predictions = pd.DataFrame({\n",
    "                'datetime': match_info['datetime'].iloc[self.sequence_length - 1: self.sequence_length - 1 + min_len],\n",
    "                'home_team': match_info['home_team'].iloc[self.sequence_length - 1: self.sequence_length - 1 + min_len],\n",
    "                'away_team': match_info['away_team'].iloc[self.sequence_length - 1: self.sequence_length - 1 + min_len],\n",
    "                'lstm_prob': lstm_probs[:min_len],\n",
    "                'draw_probability': lstm_probs[:min_len]\n",
    "            })\n",
    "\n",
    "            return predictions\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"Loading data...\")\n",
    "        df = pd.read_csv('virtual_matches_data.csv')\n",
    "        print(f\"Loaded {len(df)} matches\")\n",
    "\n",
    "        print(\"\\nTraining LSTM model...\")\n",
    "        predictor = SoccerPredictor()\n",
    "        metrics = predictor.train_model(df)\n",
    "\n",
    "        print(\"\\nLSTM Model Performance:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.3f}\")\n",
    "\n",
    "        predictor.lstm_model.save('lstm_model.keras')\n",
    "        print(\"LSTM model saved successfully.\")\n",
    "\n",
    "        print(\"\\nPredicting upcoming matches...\")\n",
    "        latest_date = pd.to_datetime(df['datetime']).max()\n",
    "        future_matches = df[pd.to_datetime(df['datetime']) > latest_date - pd.Timedelta(hours=1)]\n",
    "\n",
    "        if len(future_matches) > 0:\n",
    "            predictions = predictor.predict_draws(future_matches)\n",
    "\n",
    "            print(\"\\nDraw Probabilities:\")\n",
    "            for _, row in predictions.iterrows():\n",
    "                print(f\"{row['home_team']} vs {row['away_team']}: {row['draw_probability']:.3f}\")\n",
    "        else:\n",
    "            print(\"No upcoming matches found\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "c6310d1f5de9f5d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 19811 matches\n",
      "\n",
      "Training models...\n",
      "\u001B[1m496/496\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\n",
      "Model Performance:\n",
      "\n",
      "XGB Metrics:\n",
      "accuracy: 0.924\n",
      "precision: 0.775\n",
      "recall: 1.000\n",
      "f1: 0.873\n",
      "\n",
      "LSTM Metrics:\n",
      "accuracy: 0.994\n",
      "precision: 0.979\n",
      "recall: 0.997\n",
      "f1: 0.988\n",
      "Models saved successfully.\n",
      "\n",
      "Predicting upcoming matches...\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\n",
      "Draw Probabilities:\n",
      "ROM vs NAP: 0.156\n",
      "MIL vs FIO: 0.825\n",
      "LAZ vs INT: 0.914\n",
      "JUV vs NAP: 0.850\n",
      "MIL vs ROM: 0.243\n",
      "INT vs NAP: 0.161\n",
      "ROM vs JUV: 0.163\n",
      "LAZ vs FIO: 0.152\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dati da prevedere.",
   "id": "5c5547cee97ff7c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T22:43:58.119384Z",
     "start_time": "2024-11-21T22:43:50.888951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class VirtualOddsCollector:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',\n",
    "            'Accept': 'application/json, text/plain, */*',\n",
    "            'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "            'Accept-Language': 'en-US,en;q=0.6',\n",
    "            'Origin': 'https://www.eurobet.it',\n",
    "            'X-EB-Accept-Language': 'it_IT',\n",
    "            'X-EB-MarketId': '5',\n",
    "            'X-EB-PlatformId': '1',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Referer': 'https://www.eurobet.it/'\n",
    "        }\n",
    "        self.data_dir = Path('data')\n",
    "        self.data_dir.mkdir(exist_ok=True)\n",
    "        self.csv_filename = self.data_dir / 'virtual_odds_detail.csv'\n",
    "        self.base_url = \"https://virtualservice.eurobet.it/virtual-detail-service/virtual-schedule/services/22/sport/{}\"\n",
    "\n",
    "        print(f\"File will be saved to: {self.csv_filename}\")\n",
    "\n",
    "    def get_match_odds(self, match_code):\n",
    "        \"\"\"Get odds for a specific match\"\"\"\n",
    "        url = self.base_url.format(match_code)\n",
    "        try:\n",
    "            print(f\"Fetching data for match code: {match_code}\")\n",
    "            response = requests.get(url, headers=self.headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            if 'result' not in data or 'eventdetail' not in data['result']:\n",
    "                print(f\"No valid data found for match {match_code}\")\n",
    "                return None\n",
    "\n",
    "            event_info = data['result']['eventdetail']['eventInfo']\n",
    "            bet_groups = data['result']['eventdetail']['betGroupList']\n",
    "\n",
    "            match_data = {\n",
    "                'match_code': match_code,\n",
    "                'timestamp': datetime.fromtimestamp(event_info['eventData']/1000).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'home_team': event_info['teamHomeDescription'],\n",
    "                'away_team': event_info['teamAwayDescription'],\n",
    "                'channel': event_info['channelDescription'],\n",
    "                'event_code': event_info['eventCode'],\n",
    "                'program_code': event_info['programCode'],\n",
    "                'collection_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "\n",
    "            for bet_group in bet_groups:\n",
    "                bet_type = bet_group['betDescription']\n",
    "                market_id = bet_group['marketId']\n",
    "\n",
    "                if bet_group['oddGroupList'] and bet_group['oddGroupList'][0]['oddList']:\n",
    "                    odds = bet_group['oddGroupList'][0]['oddList']\n",
    "\n",
    "                    for odd in odds:\n",
    "                        desc = odd['oddDescription']\n",
    "                        value = odd['oddValue']\n",
    "                        result_code = odd['resultCode']\n",
    "\n",
    "                        key_base = f\"{bet_type}_{desc}\".lower().replace('/', '_').replace(' ', '_')\n",
    "                        match_data[f\"{key_base}_odds\"] = value\n",
    "                        match_data[f\"{key_base}_code\"] = result_code\n",
    "\n",
    "            print(f\"Successfully collected odds for {match_data['home_team']} vs {match_data['away_team']}\")\n",
    "            return match_data\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Network error for match {match_code}: {e}\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error for match {match_code}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for match {match_code}: {e}\")\n",
    "        return None\n",
    "\n",
    "    def collect_matches(self, match_codes):\n",
    "        \"\"\"Collect odds for multiple matches\"\"\"\n",
    "        all_matches = []\n",
    "\n",
    "        print(f\"\\nStarting collection for match codes: {match_codes}\")\n",
    "\n",
    "        for match_code in match_codes:\n",
    "            match_data = self.get_match_odds(match_code)\n",
    "            if match_data:\n",
    "                all_matches.append(match_data)\n",
    "            time.sleep(1)\n",
    "\n",
    "        if not all_matches:\n",
    "            print(\"No match data collected!\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(all_matches)\n",
    "\n",
    "        if self.csv_filename.exists():\n",
    "            try:\n",
    "                existing_df = pd.read_csv(self.csv_filename)\n",
    "                print(f\"Loaded {len(existing_df)} existing records\")\n",
    "                df = pd.concat([existing_df, df], ignore_index=True)\n",
    "                df = df.drop_duplicates(subset=['match_code', 'timestamp'], keep='last')\n",
    "                print(f\"After merging and removing duplicates: {len(df)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading existing data: {e}\")\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.sort_values('timestamp', ascending=False)\n",
    "\n",
    "        try:\n",
    "            df.to_csv(self.csv_filename, index=False)\n",
    "            print(f\"\\nSuccessfully saved data to {self.csv_filename}\")\n",
    "            print(f\"Total matches in database: {len(df)}\")\n",
    "\n",
    "            print(\"\\nPreview of saved data:\")\n",
    "            basic_cols = ['timestamp', 'home_team', 'away_team']\n",
    "            odds_cols = [col for col in df.columns if '1x2_finale' in col and 'odds' in col]\n",
    "            print(df[basic_cols + odds_cols].head())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving data: {e}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "# Variabili per generare i codici delle partite\n",
    "BASE_CODE = \"55_2402405092\"  # Codice base\n",
    "START_NUMBER = 411  # Numero iniziale\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Genera 5 codici incrementando di 2 ogni volta\n",
    "    match_codes = []\n",
    "    current_number = START_NUMBER\n",
    "\n",
    "    for _ in range(5):\n",
    "        match_code = f\"{BASE_CODE}_{current_number}\"\n",
    "        match_codes.append(match_code)\n",
    "        current_number += 2\n",
    "\n",
    "    collector = VirtualOddsCollector()\n",
    "    collector.collect_matches(match_codes)"
   ],
   "id": "a0dd4bab52375c25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File will be saved to: data\\virtual_odds_detail.csv\n",
      "\n",
      "Starting collection for match codes: ['55_2402405092_411', '55_2402405092_413', '55_2402405092_415', '55_2402405092_417', '55_2402405092_419']\n",
      "Fetching data for match code: 55_2402405092_411\n",
      "Successfully collected odds for INT vs ROM\n",
      "Fetching data for match code: 55_2402405092_413\n",
      "Successfully collected odds for WHU vs TOT\n",
      "Fetching data for match code: 55_2402405092_415\n",
      "Successfully collected odds for INT vs JUV\n",
      "Fetching data for match code: 55_2402405092_417\n",
      "Successfully collected odds for GAL vs IBB\n",
      "Fetching data for match code: 55_2402405092_419\n",
      "Successfully collected odds for LAZ vs ROM\n",
      "Loaded 16 existing records\n",
      "After merging and removing duplicates: 19 records\n",
      "\n",
      "Successfully saved data to data\\virtual_odds_detail.csv\n",
      "Total matches in database: 19\n",
      "\n",
      "Preview of saved data:\n",
      "             timestamp home_team away_team  1x2_finale_1_odds  \\\n",
      "20 2024-11-21 23:58:00       LAZ       ROM                197   \n",
      "19 2024-11-21 23:53:00       GAL       IBB                267   \n",
      "18 2024-11-21 23:48:00       INT       JUV                255   \n",
      "17 2024-11-21 23:43:00       WHU       TOT                262   \n",
      "16 2024-11-21 23:39:00       INT       ROM                214   \n",
      "\n",
      "    1x2_finale_x_odds  1x2_finale_2_odds  \n",
      "20                337                303  \n",
      "19                331                218  \n",
      "18                321                231  \n",
      "17                328                223  \n",
      "16                321                280  \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T22:51:27.908873Z",
     "start_time": "2024-11-21T22:51:00.408615Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f6cb484fc5dcd936",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 19811 matches\n",
      "\n",
      "Training LSTM model...\n",
      "\u001B[1m496/496\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\n",
      "LSTM Model Performance:\n",
      "accuracy: 0.996\n",
      "precision: 0.989\n",
      "recall: 0.997\n",
      "f1: 0.993\n",
      "LSTM model saved successfully.\n",
      "\n",
      "Predicting upcoming matches...\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\n",
      "Draw Probabilities:\n",
      "ROM vs NAP: 0.000\n",
      "MIL vs FIO: 0.906\n",
      "LAZ vs INT: 1.000\n",
      "JUV vs NAP: 0.958\n",
      "MIL vs ROM: 0.014\n",
      "INT vs NAP: 0.000\n",
      "ROM vs JUV: 0.000\n",
      "LAZ vs FIO: 0.000\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
